{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openml\n",
    "import joblib\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from tqdm.notebook import tqdm\n",
    "from copy import deepcopy as copy\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib import pyplot as plt\n",
    "from xgboost import XGBClassifier as XGBC\n",
    "from sklearn.preprocessing import RobustScaler as RS\n",
    "\n",
    "openml.config.apikey = \"4ef25cfe971a3731fddbe4fb2f6d1d98\"\n",
    "data_folder = \"/data/pereirabarataap/journal/\"\n",
    "pd.set_option(\"max.columns\", 1000)\n",
    "pd.set_option(\"max.rows\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "We use [openML](https://www.openml.org/) to get some (10) datasets for our experiments.\n",
    "\n",
    "The datasets must respect the following:\n",
    "* no missing values\n",
    "* be between 20 to 100 features wide\n",
    "* be between 100 and 5000 instances long\n",
    "* classification task-related\n",
    "    * 2 class-specific\n",
    "    * at least 100 instances per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets_df = pd.DataFrame.from_dict(openml.datasets.list_datasets()).T.dropna(how=\"any\")\n",
    "\n",
    "loc = (datasets_df[\"NumberOfMissingValues\"]==0) & \\\n",
    "      (datasets_df[\"NumberOfClasses\"]==2) & \\\n",
    "      (datasets_df[\"MinorityClassSize\"]>=100) & \\\n",
    "      (datasets_df[\"NumberOfInstances\"]<=5000) & \\\n",
    "      (datasets_df[\"NumberOfFeatures\"]<=100) & \\\n",
    "      (datasets_df[\"NumberOfFeatures\"]>=20) & \\\n",
    "      ~(datasets_df[\"name\"].str.contains(\"_\"))\n",
    "\n",
    "dids = datasets_df.loc[loc].sort_values(by=[\"NumberOfInstances\"])[\"did\"]\n",
    "dids.tolist()\n",
    "\n",
    "for did in dids:\n",
    "    dataset = openml.datasets.get_dataset(did)\n",
    "    print(did)\n",
    "    print(dataset.description)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>name</th>\n",
       "      <th>version</th>\n",
       "      <th>uploader</th>\n",
       "      <th>status</th>\n",
       "      <th>format</th>\n",
       "      <th>MajorityClassSize</th>\n",
       "      <th>MaxNominalAttDistinctValues</th>\n",
       "      <th>MinorityClassSize</th>\n",
       "      <th>NumberOfClasses</th>\n",
       "      <th>NumberOfFeatures</th>\n",
       "      <th>NumberOfInstances</th>\n",
       "      <th>NumberOfNumericFeatures</th>\n",
       "      <th>NumberOfSymbolicFeatures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>ionosphere</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>351</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>1063</td>\n",
       "      <td>kc2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>415</td>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>522</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>1510</td>\n",
       "      <td>wdbc</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>357</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>569</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40705</th>\n",
       "      <td>40705</td>\n",
       "      <td>tokyo1</td>\n",
       "      <td>1</td>\n",
       "      <td>869</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>613</td>\n",
       "      <td>2</td>\n",
       "      <td>346</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>959</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>credit-g</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1000</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>1494</td>\n",
       "      <td>qsar-biodeg</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>699</td>\n",
       "      <td>2</td>\n",
       "      <td>356</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>1055</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>1504</td>\n",
       "      <td>steel-plates-fault</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>1268</td>\n",
       "      <td>2</td>\n",
       "      <td>673</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>1941</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>1487</td>\n",
       "      <td>ozone-level-8hr</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>2374</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "      <td>2534</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>kr-vs-kp</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>1669</td>\n",
       "      <td>3</td>\n",
       "      <td>1527</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>3196</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>spambase</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>2788</td>\n",
       "      <td>2</td>\n",
       "      <td>1813</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>4601</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         did                name version uploader  status format  \\\n",
       "59        59          ionosphere       1        1  active   ARFF   \n",
       "1063    1063                 kc2       1        2  active   ARFF   \n",
       "1510    1510                wdbc       1       64  active   ARFF   \n",
       "40705  40705              tokyo1       1      869  active   ARFF   \n",
       "31        31            credit-g       1        1  active   ARFF   \n",
       "1494    1494         qsar-biodeg       1       64  active   ARFF   \n",
       "1504    1504  steel-plates-fault       1       64  active   ARFF   \n",
       "1487    1487     ozone-level-8hr       1       64  active   ARFF   \n",
       "3          3            kr-vs-kp       1        1  active   ARFF   \n",
       "44        44            spambase       1        1  active   ARFF   \n",
       "\n",
       "      MajorityClassSize MaxNominalAttDistinctValues MinorityClassSize  \\\n",
       "59                  225                           2               126   \n",
       "1063                415                           2               107   \n",
       "1510                357                           2               212   \n",
       "40705               613                           2               346   \n",
       "31                  700                          10               300   \n",
       "1494                699                           2               356   \n",
       "1504               1268                           2               673   \n",
       "1487               2374                           2               160   \n",
       "3                  1669                           3              1527   \n",
       "44                 2788                           2              1813   \n",
       "\n",
       "      NumberOfClasses NumberOfFeatures NumberOfInstances  \\\n",
       "59                  2               35               351   \n",
       "1063                2               22               522   \n",
       "1510                2               31               569   \n",
       "40705               2               45               959   \n",
       "31                  2               21              1000   \n",
       "1494                2               42              1055   \n",
       "1504                2               34              1941   \n",
       "1487                2               73              2534   \n",
       "3                   2               37              3196   \n",
       "44                  2               58              4601   \n",
       "\n",
       "      NumberOfNumericFeatures NumberOfSymbolicFeatures  \n",
       "59                         34                        1  \n",
       "1063                       21                        1  \n",
       "1510                       30                        1  \n",
       "40705                      42                        3  \n",
       "31                          7                       14  \n",
       "1494                       41                        1  \n",
       "1504                       33                        1  \n",
       "1487                       72                        1  \n",
       "3                           0                       37  \n",
       "44                         57                        1  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual inspection yields the following 10 datasets\n",
    "dids = [59, 1063, 1510, 40705, 31, 1494, 1504, 1487, 3, 44]\n",
    "datasets_df.loc[dids].sort_values(by=[\"NumberOfInstances\"]).drop(columns=[\"NumberOfInstancesWithMissingValues\", \"NumberOfMissingValues\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature and Target Manipulation\n",
    "Before testing how different methods perform in crosslier detection, we need to generate crossliers to be detected.<br>\n",
    "The experimental setup can divided in:\n",
    "* symmetric\n",
    "    * both classes have the same proportion of crossliers\n",
    "* asymmetric\n",
    "    * the proportion of crossliers in both classes can be different\n",
    "\n",
    "#### Symmetric\n",
    "There are 2 parameters in this setup:\n",
    "* $\\rho_y\\in \\{.01,.02,.03,.04,.05,.06,.07,.08,.09,.1\\}$\n",
    "* $\\rho_x\\in \\{0,  .05, .1,.15, .2, .25, .3, .35, .4, .45\\}$\n",
    "\n",
    " $\\rho_y$ represents the proportion of instances with labels swapped in each class.<br>\n",
    " $\\rho_x$ represents the proportion of attributes of which the values are replaced in label-swapped instances.<br>\n",
    "\n",
    "#### Asymmetric\n",
    "There are 4 parameters in this setup:\n",
    "* $\\rho_{y+} \\in \\{.01, .02,.03, .04,.05, .06,.07, .08,.09,  .1\\}$\n",
    "* $\\rho_{y-} \\in \\{.01, .02,.03, .04,.05, .06,.07, .08,.09,  .1\\}$\n",
    "* $\\rho_{x+} \\in \\{0,   .05, .1, .15, .2, .25, .3, .35, .4, .45\\}$\n",
    "* $\\rho_{x-} \\in \\{0,   .05, .1, .15, .2, .25, .3, .35, .4, .45\\}$\n",
    "\n",
    " $\\rho_{y+}$ represents the proportion of instances with labels swapped: they originally belong to the positive class.<br>\n",
    " $\\rho_{y-}$ represents the proportion of instances with labels swapped: they originally belong to the negative class.<br>\n",
    " $\\rho_{x+}$ represents the proportion of attributes of which the values are replaced in label-swapped instances: the instances originally belong to the positive class.<br>\n",
    " $\\rho_{x-}$ represents the proportion of attributes of which the values are replaced in label-swapped instances: the instances originally belong to the negative class.<br>\n",
    "\n",
    "The replacement simulates real-world fraud in which manipulation of feature values towards those of another label further masks the real label.<br>\n",
    "Replacement values are drawn from <b>univariate</b> distributions with parameters estimated from the respective attributes belonging to the class being mimicked.<br>\n",
    "To note, for both <i>symmetric</i> and <i>asymmetric</i> setups:\n",
    "* Each dataset will have <b>50</b> random initialisations for each set of parameters\n",
    "* Attributes to be replaced:\n",
    "    * are chosen by either:\n",
    "        * <b>random</b> selection, where attributes are selected randomly for each instance\n",
    "        * <b>category</b> selection, where each class has a set of random attributes to mimic (1 set of attributes per class)\n",
    "        * <b>consistent</b> selection, where a single set of random attributes are selected for all label-swapped instances regardless of class\n",
    "    * are modelled as:\n",
    "        * normal distributions $\\mathcal{N}(\\hat{\\mu}, \\hat{\\sigma})$ for numerical attributes\n",
    "        * multinomial distributions for categorical attributes\n",
    "    * have distribution parameters either:\n",
    "        * <b>clean</b>, estimated <i>a priori</i> label swaps\n",
    "        * <b>noisy</b>, estimated <i>a posteriori</i> label swaps\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_apply(y):\n",
    "    # this function is required by XGBoost\n",
    "    # since it cannot handle dummy_variables well\n",
    "    # dummy names cannot contain \"<\" nor \",\"\n",
    "    try:\n",
    "        return (y.replace(\"<\", \"lt\")).replace(\",\", \"c\")\n",
    "    except:\n",
    "        return y\n",
    "    \n",
    "def parallel_symmetric_setup(seed, did_folder, X, y, df, attribute_names, categorical_indicator, y_pos, y_neg, X_clean_pos, X_clean_neg):\n",
    "    seed_folder = did_folder + \"seed=\" + str(seed) + \"/\"\n",
    "    try:\n",
    "        os.mkdir(seed_folder)\n",
    "    except:\n",
    "        shutil.rmtree(seed_folder)\n",
    "        os.mkdir(seed_folder)\n",
    "    np.random.seed(seed)\n",
    "    for roh_y_prct in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "        roh_y_folder = seed_folder + \"roh_y=\" + str(roh_y_prct) + \"/\"\n",
    "        try:\n",
    "            os.mkdir(roh_y_folder)\n",
    "        except:\n",
    "            shutil.rmtree(roh_y_folder)\n",
    "            os.mkdir(roh_y_folder)\n",
    "        roh_y = roh_y_prct/100\n",
    "        # number of instances to label swap\n",
    "        roh_y_pos_n = int(np.ceil(roh_y*X_clean_pos.shape[0]))\n",
    "        roh_y_neg_n = int(np.ceil(roh_y*X_clean_neg.shape[0]))\n",
    "        for roh_x_prct in [0, 5, 10, 15, 20, 25, 30, 35, 40, 45]:\n",
    "            roh_x_folder = roh_y_folder + \"roh_x=\" + str(roh_x_prct) + \"/\"\n",
    "            try:\n",
    "                os.mkdir(roh_x_folder)\n",
    "            except:\n",
    "                shutil.rmtree(roh_x_folder)\n",
    "                os.mkdir(roh_x_folder)\n",
    "            roh_x = roh_x_prct/100\n",
    "            # number of attributes to swap\n",
    "            roh_x_n = int(np.ceil(roh_x*X.shape[1]))\n",
    "            # label-swap instance locations (index)\n",
    "            roh_y_pos_loc = np.random.choice(X_clean_pos.index, roh_y_pos_n, replace=False) # will be present in X_noisy_neg\n",
    "            roh_y_neg_loc = np.random.choice(X_clean_neg.index, roh_y_neg_n, replace=False) # will be present in X_noisy_pos    \n",
    "            if roh_x_n == 0:\n",
    "                # no attribute replacement is required, only label swap\n",
    "                corrupted_df = copy(df)\n",
    "                corrupted_df.loc[roh_y_pos_loc, \"class\"] = y_neg\n",
    "                corrupted_df.loc[roh_y_neg_loc, \"class\"] = y_pos\n",
    "                # saving corrupted df\n",
    "                joblib.dump(corrupted_df, roh_x_folder + \"corrupted_df.pkl\")\n",
    "                corrupted_df.to_csv(roh_x_folder + \"corrupted_df.csv\", index=False)\n",
    "            else:\n",
    "                X_noisy_pos = pd.concat((\n",
    "                    copy(X.loc[roh_y_neg_loc]), # getting swap examples from other class\n",
    "                    copy(X_clean_pos.drop(labels=roh_y_pos_loc)) # dropping examples that are given to other class\n",
    "                ))\n",
    "                X_noisy_neg = pd.concat((\n",
    "                    copy(X.loc[roh_y_pos_loc]), # getting swap examples from other class\n",
    "                    copy(X_clean_neg.drop(labels=roh_y_neg_loc)) # dropping examples that are given to other class\n",
    "                ))\n",
    "                # random selection\n",
    "                # each label-swapped instance has its own set of random attributes to replace\n",
    "                random_folder = roh_x_folder + \"random/\"\n",
    "                try:\n",
    "                    os.mkdir(random_folder)\n",
    "                except:\n",
    "                    shutil.rmtree(random_folder)\n",
    "                    os.mkdir(random_folder)\n",
    "                random_clean_X = copy(X)\n",
    "                random_noisy_X = copy(X)\n",
    "                for roh_y_pos_index in roh_y_pos_loc:\n",
    "                    replace_attribute_indexs = np.random.choice(range(X.shape[1]), roh_x_n, replace=False)\n",
    "                    replace_attribute_names = attribute_names[replace_attribute_indexs]\n",
    "                    replace_categorical_indicators = categorical_indicator[replace_attribute_indexs]\n",
    "                    # for each attribute being replaced\n",
    "                    clean_replacement_values = []\n",
    "                    noisy_replacement_values = []\n",
    "                    for i in range(roh_x_n):\n",
    "                        replace_attribute_name = replace_attribute_names[i]\n",
    "                        replace_categorical_indicator = replace_categorical_indicators[i]\n",
    "                        if replace_categorical_indicator:\n",
    "                            # is categorical\n",
    "                            clean_replacement_value = np.random.choice(X_clean_neg[replace_attribute_name], 1)\n",
    "                            noisy_replacement_value = np.random.choice(X_noisy_neg[replace_attribute_name], 1)\n",
    "                        else:\n",
    "                            # is numerical\n",
    "                            clean_mu = np.mean(X_clean_neg[replace_attribute_name])\n",
    "                            clean_sig = np.std(X_clean_neg[replace_attribute_name], ddof=1)\n",
    "                            clean_replacement_value = np.random.normal(clean_mu, clean_sig, 1)\n",
    "                            noisy_mu = np.mean(X_noisy_neg[replace_attribute_name])\n",
    "                            noisy_sig = np.std(X_noisy_neg[replace_attribute_name], ddof=1)\n",
    "                            noisy_replacement_value = np.random.normal(noisy_mu, noisy_sig, 1)\n",
    "                        clean_replacement_values += [clean_replacement_value[0]]\n",
    "                        noisy_replacement_values += [noisy_replacement_value[0]]\n",
    "                    random_clean_X.loc[roh_y_pos_index, replace_attribute_names] = clean_replacement_values\n",
    "                    random_noisy_X.loc[roh_y_pos_index, replace_attribute_names] = noisy_replacement_values\n",
    "                for roh_y_neg_index in roh_y_neg_loc:\n",
    "                    replace_attribute_indexs = np.random.choice(range(X.shape[1]), roh_x_n, replace=False)\n",
    "                    replace_attribute_names = attribute_names[replace_attribute_indexs]\n",
    "                    replace_categorical_indicators = categorical_indicator[replace_attribute_indexs]\n",
    "                    # for each attribute being replaced\n",
    "                    clean_replacement_values = []\n",
    "                    noisy_replacement_values = []\n",
    "                    for i in range(roh_x_n):\n",
    "                        replace_attribute_name = replace_attribute_names[i]\n",
    "                        replace_categorical_indicator = replace_categorical_indicators[i]\n",
    "                        if replace_categorical_indicator:\n",
    "                            # is categorical\n",
    "                            clean_replacement_value = np.random.choice(X_clean_pos[replace_attribute_name], 1)\n",
    "                            noisy_replacement_value = np.random.choice(X_noisy_pos[replace_attribute_name], 1)\n",
    "                        else:\n",
    "                            # is numerical\n",
    "                            clean_mu = np.mean(X_clean_pos[replace_attribute_name])\n",
    "                            clean_sig = np.std(X_clean_pos[replace_attribute_name], ddof=1)\n",
    "                            clean_replacement_value = np.random.normal(clean_mu, clean_sig, 1)\n",
    "                            noisy_mu = np.mean(X_noisy_pos[replace_attribute_name])\n",
    "                            noisy_sig = np.std(X_noisy_pos[replace_attribute_name], ddof=1)\n",
    "                            noisy_replacement_value = np.random.normal(noisy_mu, noisy_sig, 1)\n",
    "                        clean_replacement_values += [clean_replacement_value[0]]\n",
    "                        noisy_replacement_values += [noisy_replacement_value[0]]\n",
    "                    random_clean_X.loc[roh_y_neg_index, replace_attribute_names] = clean_replacement_values\n",
    "                    random_noisy_X.loc[roh_y_neg_index, replace_attribute_names] = noisy_replacement_values\n",
    "                corrupted_clean_df = pd.concat((copy(random_clean_X), copy(y)), axis=1)\n",
    "                corrupted_clean_df.loc[roh_y_pos_loc, \"class\"] = y_neg\n",
    "                corrupted_clean_df.loc[roh_y_neg_loc, \"class\"] = y_pos\n",
    "                corrupted_noisy_df = pd.concat((copy(random_noisy_X), copy(y)), axis=1)\n",
    "                corrupted_noisy_df.loc[roh_y_pos_loc, \"class\"] = y_neg\n",
    "                corrupted_noisy_df.loc[roh_y_neg_loc, \"class\"] = y_pos\n",
    "                joblib.dump(corrupted_clean_df, random_folder + \"corrupted_clean_df.pkl\")\n",
    "                joblib.dump(corrupted_noisy_df, random_folder + \"corrupted_noisy_df.pkl\")\n",
    "                corrupted_clean_df.to_csv(random_folder + \"corrupted_clean_df.csv\", index=False)\n",
    "                corrupted_noisy_df.to_csv(random_folder + \"corrupted_noisy_df.csv\", index=False)\n",
    "\n",
    "                # category selection\n",
    "                # each class has a set of random attributes to mimic (1 set of attributes per class)\n",
    "                category_folder = roh_x_folder + \"category/\"\n",
    "                try:\n",
    "                    os.mkdir(category_folder)\n",
    "                except:\n",
    "                    shutil.rmtree(category_folder)\n",
    "                    os.mkdir(category_folder)\n",
    "                category_clean_X = copy(X)\n",
    "                category_noisy_X = copy(X)\n",
    "                replace_attribute_indexs = np.random.choice(range(X.shape[1]), roh_x_n, replace=False)\n",
    "                replace_attribute_names = attribute_names[replace_attribute_indexs]\n",
    "                replace_categorical_indicators = categorical_indicator[replace_attribute_indexs]\n",
    "                for roh_y_pos_index in roh_y_pos_loc:\n",
    "                    clean_replacement_values = []\n",
    "                    noisy_replacement_values = []\n",
    "                    for i in range(roh_x_n):\n",
    "                        replace_attribute_name = replace_attribute_names[i]\n",
    "                        replace_categorical_indicator = replace_categorical_indicators[i]\n",
    "                        if replace_categorical_indicator:\n",
    "                            # is categorical\n",
    "                            clean_replacement_value = np.random.choice(X_clean_neg[replace_attribute_name], 1)\n",
    "                            noisy_replacement_value = np.random.choice(X_noisy_neg[replace_attribute_name], 1)\n",
    "                        else:\n",
    "                            # is numerical\n",
    "                            clean_mu = np.mean(X_clean_neg[replace_attribute_name])\n",
    "                            clean_sig = np.std(X_clean_neg[replace_attribute_name], ddof=1)\n",
    "                            clean_replacement_value = np.random.normal(clean_mu, clean_sig, 1)\n",
    "                            noisy_mu = np.mean(X_noisy_neg[replace_attribute_name])\n",
    "                            noisy_sig = np.std(X_noisy_neg[replace_attribute_name], ddof=1)\n",
    "                            noisy_replacement_value = np.random.normal(noisy_mu, noisy_sig, 1)\n",
    "                        clean_replacement_values += [clean_replacement_value[0]]\n",
    "                        noisy_replacement_values += [noisy_replacement_value[0]]\n",
    "                    category_clean_X.loc[roh_y_pos_index, replace_attribute_names] = clean_replacement_values\n",
    "                    category_noisy_X.loc[roh_y_pos_index, replace_attribute_names] = noisy_replacement_values                    \n",
    "                replace_attribute_indexs = np.random.choice(range(X.shape[1]), roh_x_n, replace=False)\n",
    "                replace_attribute_names = attribute_names[replace_attribute_indexs]\n",
    "                replace_categorical_indicators = categorical_indicator[replace_attribute_indexs]\n",
    "                for roh_y_neg_index in roh_y_neg_loc:\n",
    "                    clean_replacement_values = []\n",
    "                    noisy_replacement_values = []\n",
    "                    for i in range(roh_x_n):\n",
    "                        replace_attribute_name = replace_attribute_names[i]\n",
    "                        replace_categorical_indicator = replace_categorical_indicators[i]\n",
    "                        if replace_categorical_indicator:\n",
    "                            # is categorical\n",
    "                            clean_replacement_value = np.random.choice(X_clean_pos[replace_attribute_name], 1)\n",
    "                            noisy_replacement_value = np.random.choice(X_noisy_pos[replace_attribute_name], 1)\n",
    "                        else:\n",
    "                            # is numerical\n",
    "                            clean_mu = np.mean(X_clean_pos[replace_attribute_name])\n",
    "                            clean_sig = np.std(X_clean_pos[replace_attribute_name], ddof=1)\n",
    "                            clean_replacement_value = np.random.normal(clean_mu, clean_sig, 1)\n",
    "                            noisy_mu = np.mean(X_noisy_pos[replace_attribute_name])\n",
    "                            noisy_sig = np.std(X_noisy_pos[replace_attribute_name], ddof=1)\n",
    "                            noisy_replacement_value = np.random.normal(noisy_mu, noisy_sig, 1)\n",
    "                        clean_replacement_values += [clean_replacement_value[0]]\n",
    "                        noisy_replacement_values += [noisy_replacement_value[0]]\n",
    "                    category_clean_X.loc[roh_y_neg_index, replace_attribute_names] = clean_replacement_values\n",
    "                    category_noisy_X.loc[roh_y_neg_index, replace_attribute_names] = noisy_replacement_values\n",
    "                corrupted_clean_df = pd.concat((copy(category_clean_X), copy(y)), axis=1)\n",
    "                corrupted_clean_df.loc[roh_y_pos_loc, \"class\"] = y_neg\n",
    "                corrupted_clean_df.loc[roh_y_neg_loc, \"class\"] = y_pos\n",
    "                corrupted_noisy_df = pd.concat((copy(category_noisy_X), copy(y)), axis=1)\n",
    "                corrupted_noisy_df.loc[roh_y_pos_loc, \"class\"] = y_neg\n",
    "                corrupted_noisy_df.loc[roh_y_neg_loc, \"class\"] = y_pos\n",
    "                joblib.dump(corrupted_clean_df, category_folder + \"corrupted_clean_df.pkl\")\n",
    "                joblib.dump(corrupted_noisy_df, category_folder + \"corrupted_noisy_df.pkl\")\n",
    "                corrupted_clean_df.to_csv(category_folder + \"corrupted_clean_df.csv\", index=False)\n",
    "                corrupted_noisy_df.to_csv(category_folder + \"corrupted_noisy_df.csv\", index=False)\n",
    "\n",
    "                # consistent selection\n",
    "                # same attributes are selected for every label-swapped instance regardless of class\n",
    "                consistent_folder = roh_x_folder + \"consistent/\"\n",
    "                try:\n",
    "                    os.mkdir(consistent_folder)\n",
    "                except:\n",
    "                    shutil.rmtree(consistent_folder)\n",
    "                    os.mkdir(consistent_folder)\n",
    "                consistent_clean_X = copy(X)\n",
    "                consistent_noisy_X = copy(X)\n",
    "                replace_attribute_indexs = np.random.choice(range(X.shape[1]), roh_x_n, replace=False)\n",
    "                replace_attribute_names = attribute_names[replace_attribute_indexs]\n",
    "                replace_categorical_indicators = categorical_indicator[replace_attribute_indexs]\n",
    "                for roh_y_pos_index in roh_y_pos_loc:\n",
    "                    clean_replacement_values = []\n",
    "                    noisy_replacement_values = []\n",
    "                    for i in range(roh_x_n):\n",
    "                        replace_attribute_name = replace_attribute_names[i]\n",
    "                        replace_categorical_indicator = replace_categorical_indicators[i]\n",
    "                        if replace_categorical_indicator:\n",
    "                            # is categorical\n",
    "                            clean_replacement_value = np.random.choice(X_clean_neg[replace_attribute_name], 1)\n",
    "                            noisy_replacement_value = np.random.choice(X_noisy_neg[replace_attribute_name], 1)\n",
    "                        else:\n",
    "                            # is numerical\n",
    "                            clean_mu = np.mean(X_clean_neg[replace_attribute_name])\n",
    "                            clean_sig = np.std(X_clean_neg[replace_attribute_name], ddof=1)\n",
    "                            clean_replacement_value = np.random.normal(clean_mu, clean_sig, 1)\n",
    "                            noisy_mu = np.mean(X_noisy_neg[replace_attribute_name])\n",
    "                            noisy_sig = np.std(X_noisy_neg[replace_attribute_name], ddof=1)\n",
    "                            noisy_replacement_value = np.random.normal(noisy_mu, noisy_sig, 1)\n",
    "                        clean_replacement_values += [clean_replacement_value[0]]\n",
    "                        noisy_replacement_values += [noisy_replacement_value[0]]\n",
    "                    consistent_clean_X.loc[roh_y_pos_index, replace_attribute_names] = clean_replacement_values\n",
    "                    consistent_noisy_X.loc[roh_y_pos_index, replace_attribute_names] = noisy_replacement_values                    \n",
    "                for roh_y_neg_index in roh_y_neg_loc:\n",
    "                    clean_replacement_values = []\n",
    "                    noisy_replacement_values = []\n",
    "                    for i in range(roh_x_n):\n",
    "                        replace_attribute_name = replace_attribute_names[i]\n",
    "                        replace_categorical_indicator = replace_categorical_indicators[i]\n",
    "                        if replace_categorical_indicator:\n",
    "                            # is categorical\n",
    "                            clean_replacement_value = np.random.choice(X_clean_pos[replace_attribute_name], 1)\n",
    "                            noisy_replacement_value = np.random.choice(X_noisy_pos[replace_attribute_name], 1)\n",
    "                        else:\n",
    "                            # is numerical\n",
    "                            clean_mu = np.mean(X_clean_pos[replace_attribute_name])\n",
    "                            clean_sig = np.std(X_clean_pos[replace_attribute_name], ddof=1)\n",
    "                            clean_replacement_value = np.random.normal(clean_mu, clean_sig, 1)\n",
    "                            noisy_mu = np.mean(X_noisy_pos[replace_attribute_name])\n",
    "                            noisy_sig = np.std(X_noisy_pos[replace_attribute_name], ddof=1)\n",
    "                            noisy_replacement_value = np.random.normal(noisy_mu, noisy_sig, 1)\n",
    "                        clean_replacement_values += [clean_replacement_value[0]]\n",
    "                        noisy_replacement_values += [noisy_replacement_value[0]]\n",
    "                    consistent_clean_X.loc[roh_y_neg_index, replace_attribute_names] = clean_replacement_values\n",
    "                    consistent_noisy_X.loc[roh_y_neg_index, replace_attribute_names] = noisy_replacement_values\n",
    "                corrupted_clean_df = pd.concat((copy(consistent_clean_X), copy(y)), axis=1)\n",
    "                corrupted_clean_df.loc[roh_y_pos_loc, \"class\"] = y_neg\n",
    "                corrupted_clean_df.loc[roh_y_neg_loc, \"class\"] = y_pos\n",
    "                corrupted_noisy_df = pd.concat((copy(consistent_noisy_X), copy(y)), axis=1)\n",
    "                corrupted_noisy_df.loc[roh_y_pos_loc, \"class\"] = y_neg\n",
    "                corrupted_noisy_df.loc[roh_y_neg_loc, \"class\"] = y_pos\n",
    "                joblib.dump(corrupted_clean_df, consistent_folder + \"corrupted_clean_df.pkl\")\n",
    "                joblib.dump(corrupted_noisy_df, consistent_folder + \"corrupted_noisy_df.pkl\")\n",
    "                corrupted_clean_df.to_csv(consistent_folder + \"corrupted_clean_df.csv\", index=False)\n",
    "                corrupted_noisy_df.to_csv(consistent_folder + \"corrupted_noisy_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e16ee8ca934dbdbc251921c0ac619d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:openml.datasets.dataset:Data pickle file already exists and is up to date.\n",
      "DEBUG:openml.datasets.dataset:Data pickle file already exists and is up to date.\n",
      "DEBUG:openml.datasets.dataset:Data pickle file already exists and is up to date.\n",
      "DEBUG:openml.datasets.dataset:Data pickle file already exists and is up to date.\n",
      "DEBUG:openml.datasets.dataset:Data pickle file already exists and is up to date.\n",
      "DEBUG:openml.datasets.dataset:Data pickle file already exists and is up to date.\n",
      "DEBUG:openml.datasets.dataset:Data pickle file already exists and is up to date.\n",
      "DEBUG:openml.datasets.dataset:Data pickle file already exists and is up to date.\n",
      "DEBUG:openml.datasets.dataset:Data pickle file already exists and is up to date.\n",
      "DEBUG:openml.datasets.dataset:Data pickle file already exists and is up to date.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# SYMETRIC\n",
    "# SETUP\n",
    "data_folder = \"/data/pereirabarataap/journal/symmetric/dids/\"\n",
    "try:\n",
    "    os.mkdir(data_folder)\n",
    "except:\n",
    "    shutil.rmtree(data_folder)\n",
    "    os.mkdir(data_folder)\n",
    "seeds = range(50)\n",
    "for did in tqdm(dids):\n",
    "    did_folder = data_folder + \"did=\" + str(did) + \"/\"\n",
    "    try:\n",
    "        os.mkdir(did_folder)\n",
    "    except:\n",
    "        shutil.rmtree(did_folder)\n",
    "        os.mkdir(did_folder)\n",
    "    dataset = openml.datasets.get_dataset(did)\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        dataset_format='dataframe',\n",
    "        target=dataset.default_target_attribute\n",
    "    )\n",
    "    categorical_indicator = np.array(categorical_indicator)\n",
    "    X = X.apply(lambda x: x.apply(lambda y: in_apply(y)))\n",
    "    attribute_names = np.array(range(X.shape[1])).astype(str)\n",
    "    X.columns = attribute_names\n",
    "    df = pd.concat((copy(X), copy(y)), axis=1)\n",
    "    df.columns = attribute_names.tolist() + [\"class\"]\n",
    "    y = copy(df[\"class\"])\n",
    "    \n",
    "    joblib.dump(df, did_folder+\"df.pkl\")\n",
    "    df.to_csv(did_folder+\"df.csv\", index=False)\n",
    "    \n",
    "    y_pos, y_neg = y.unique()\n",
    "    X_clean_pos = copy(X.loc[y==y_pos]) # clean positive attributes\n",
    "    X_clean_neg = copy(X.loc[y==y_neg]) # clean negative attributes\n",
    "    \n",
    "    Parallel(n_jobs=len(seeds), backend=\"loky\")(delayed(parallel_symmetric_setup)(\n",
    "        seed=copy(seed),\n",
    "        did_folder=copy(did_folder),\n",
    "        X=copy(X),\n",
    "        y=copy(y),\n",
    "        df=copy(df),\n",
    "        attribute_names=copy(attribute_names),\n",
    "        categorical_indicator=copy(categorical_indicator),\n",
    "        y_pos=copy(y_pos),\n",
    "        y_neg=copy(y_neg),\n",
    "        X_clean_pos=copy(X_clean_pos),\n",
    "        X_clean_neg=copy(X_clean_neg),\n",
    "    ) for seed in seeds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
